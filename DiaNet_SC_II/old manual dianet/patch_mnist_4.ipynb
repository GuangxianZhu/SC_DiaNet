{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 49, 25])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# load patches data from files\n",
    "train_images_patches = torch.load('data/mnist77_train.pt')\n",
    "test_images_patches = torch.load('data/mnist77_test.pt')\n",
    "\n",
    "# get the label from datasets.MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "test_labels = [label for _, label in test_dataset]\n",
    "train_labels = torch.LongTensor(train_labels)\n",
    "test_labels = torch.LongTensor(test_labels)\n",
    "\n",
    "# make them to be PyTorch tensors, and dataloader\n",
    "# train_dataset = torch.utils.data.TensorDataset(train_images_patches[:100], train_labels[:100])\n",
    "# test_dataset = torch.utils.data.TensorDataset(test_images_patches[:100], test_labels[:100])\n",
    "train_dataset = torch.utils.data.TensorDataset(train_images_patches, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_images_patches, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# test dataloader\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model\n",
    "# define sub model first\n",
    "class SubModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(SubModel, self).__init__()\n",
    "        self.fc0 = nn.Linear(13, 11, bias=False)\n",
    "        self.fc1 = nn.Linear(11, 9, bias=False)\n",
    "        self.fc2 = nn.Linear(9, 7, bias=False)\n",
    "        self.fc3 = nn.Linear(7, 5, bias=False)\n",
    "        self.fc4 = nn.Linear(5, 3, bias=False)\n",
    "        self.fc5 = nn.Linear(3, 1, bias=False)\n",
    "        # masks\n",
    "        self.mask0 = self.generate_fstmask(13, 11)\n",
    "        self.mask0 = self.mask0.to(device)\n",
    "        self.mask1 = self.generate_mask(11, 9)\n",
    "        self.mask1 = self.mask1.to(device)\n",
    "        self.mask2 = self.generate_mask(9, 7)\n",
    "        self.mask2 = self.mask2.to(device)\n",
    "        self.mask3 = self.generate_mask(7, 5)\n",
    "        self.mask3 = self.mask3.to(device)\n",
    "        self.mask4 =self.generate_mask(5, 3)\n",
    "        self.mask4 = self.mask4.to(device)\n",
    "        self.mask5 = self.generate_mask(3, 1)\n",
    "        self.mask5 = self.mask5.to(device)\n",
    "\n",
    "        self.logg = False\n",
    "    \n",
    "    def generate_fstmask(self, in_dim, out_dim):\n",
    "        assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (in_dim-out_dim==2), \"in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "        mask = torch.zeros(out_dim, in_dim)\n",
    "        for i in range(out_dim):\n",
    "            if i % 2 == 0:  # For every second row\n",
    "                start_index = i  # Determine start index for the 1's in this row\n",
    "                mask[i, start_index:start_index+3] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def generate_mask(self, in_dim, out_dim):\n",
    "        assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (in_dim-out_dim==2), \"main_mid_mask: in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "        mask = torch.zeros(out_dim, in_dim)\n",
    "        for i in range(out_dim):\n",
    "            if i % 2 == 0:  # For every second row\n",
    "                idx_a = max(0, i-2)\n",
    "                adx_b = min(max(0, i), in_dim-1)\n",
    "                idx_c = min(max(0, i+1), in_dim-1)\n",
    "                idx_d = min(max(0, i+2), in_dim-1)\n",
    "                idx_e = min(max(0, i+4), in_dim-1)\n",
    "                # print(idx_a, adx_b, idx_c, idx_d, idx_e)\n",
    "                index_list = [idx_a, adx_b, idx_c, idx_d, idx_e]\n",
    "                mask[i, index_list] = 1\n",
    "        \n",
    "        return mask \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == 25, \"x.shape[1] must be 25, but got {}\".format(x.shape[1])\n",
    "        assert len(x.shape) == 2, \"len(x.shape) must be 2, but got {}\".format(len(x.shape))\n",
    "\n",
    "        self.fc0.weight.data *= self.mask0\n",
    "        x0 = self.fc0(x[:, 0:13]) # x0(b,11)\n",
    "        x0 = torch.tanh(x0)\n",
    "        \n",
    "        # insert x[:, 13:18] to x0[1], x0[3], x0[5], x0[7], x0[9]\n",
    "        assert torch.sum(x0[:, [1,3,5,7,9]]) == 0, \"x0[:, [1,3,5,7,9]] must be 0, but got {}\".format(x0[:, [1,3,5,7,9]])\n",
    "        x0_copy = x0.clone()\n",
    "        x0_copy[:, [1,3,5,7,9]] += x[:, [13,14,15,16,17]]\n",
    "        x0 = x0_copy\n",
    "        self.fc1.weight.data *= self.mask1\n",
    "        x1 = self.fc1(x0)\n",
    "        x1 = torch.tanh(x1)\n",
    "\n",
    "        # insert x[:, 18:22] to x1[1], x1[3], x1[5], x1[7]\n",
    "        assert torch.sum(x1[:, [1,3,5,7]]) == 0, \"x1[:, [1,3,5,7]] must be 0, but got {}\".format(x1[:, [1,3,5,7]])\n",
    "        x1_copy = x1.clone()\n",
    "        x1_copy[:, [1,3,5,7]] += x[:, [18,19,20,21]]\n",
    "        x1 = x1_copy\n",
    "        self.fc2.weight.data *= self.mask2\n",
    "        x2 = self.fc2(x1)\n",
    "        x2_copy = x2.clone()\n",
    "        x2_copy[:,[0,2,4,6]] += x0[:, [2,4,6,8]] # jump connection\n",
    "        x2 = x2_copy\n",
    "        x2 = torch.tanh(x2)\n",
    "\n",
    "        # insert x[:, 22:25] to x2[1], x2[3], x2[5]\n",
    "        assert torch.sum(x2[:, [1,3,5]]) == 0, \"x2[:, [1,3,5]] must be 0, but got {}\".format(x2[:, [1,3,5]])\n",
    "        x2_copy = x2.clone()\n",
    "        x2_copy[:, [1,3,5]] += x[:, [22,23,24]]\n",
    "        x2 = x2_copy\n",
    "        self.fc3.weight.data *= self.mask3\n",
    "        x3 = self.fc3(x2)\n",
    "        x3_copy = x3.clone()\n",
    "        x3_copy[:, [0,2,4]] += x1[:, [2,4,6]] # jump connection\n",
    "        x3 = x3_copy\n",
    "        # no insert from now on(fc3)\n",
    "        x3 = torch.tanh(x3)\n",
    "\n",
    "        assert torch.sum(x3[:, [1,3]]) == 0, \"x3[:, [1,3]] must be 0, but got {}\".format(x3[:, [1,3]])\n",
    "        # no insert from now on(fc4)\n",
    "        self.fc4.weight.data *= self.mask4\n",
    "        x4 = self.fc4(x3)\n",
    "        x4_copy = x4.clone()\n",
    "        x4_copy[:, [0,2]] += x2[:, [2,4]] # jump connection\n",
    "        x4 = x4_copy\n",
    "        x4 = torch.tanh(x4)\n",
    "\n",
    "        assert torch.sum(x4[:, [1]]) == 0, \"x4[:, [1]] must be 0, but got {}\".format(x4[:, [1]])\n",
    "        # no insert from now on(fc5)\n",
    "        self.fc5.weight.data *= self.mask5\n",
    "        x5 = self.fc5(x4)\n",
    "        x5_copy = x5.clone()\n",
    "        x5_copy[:, [0]] += x3[:, [2]] # jump connection\n",
    "        x5 = x5_copy\n",
    "        x5 = torch.tanh(x5)\n",
    "\n",
    "\n",
    "        if self.logg: print(x0, '\\n', x1, '\\n',\n",
    "                            x2, '\\n', x3, '\\n', x4, '\\n', x5)\n",
    "\n",
    "        return x5\n",
    "\n",
    "# test model use randn input\n",
    "# model = SubModel()\n",
    "# x = torch.randn(1, 25)\n",
    "# model(x)\n",
    "\n",
    "# define main model\n",
    "# main model contain 49 sub models, and concat the 49 submodels' output to a 49-dim vector\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self, device) -> None:\n",
    "        super(MainModel, self).__init__()\n",
    "        self.submodels = nn.ModuleList([SubModel(device) for _ in range(49)])\n",
    "        self.logg = False\n",
    "\n",
    "        self.fc0 = nn.Linear(27, 33, bias=False)\n",
    "        self.fc1 = nn.Linear(33, 31, bias=False)\n",
    "        self.fc2 = nn.Linear(31, 29, bias=False)\n",
    "        self.fc3 = nn.Linear(29, 27, bias=False)\n",
    "        self.fc4 = nn.Linear(27, 25, bias=False)\n",
    "        self.fc5 = nn.Linear(25, 23, bias=False)\n",
    "        self.fc6 = nn.Linear(23, 21, bias=False)\n",
    "        self.fc7 = nn.Linear(21, 19, bias=False)\n",
    "\n",
    "        self.mask0 = self.main_fst_mask(27, 33)\n",
    "        self.mask0 = self.mask0.to(device)\n",
    "        self.mask1 = self.main_mid_mask(33, 31)\n",
    "        self.mask1 = self.mask1.to(device)\n",
    "        self.mask2 = self.main_mid_mask(31, 29)\n",
    "        self.mask2 = self.mask2.to(device)\n",
    "        self.mask3 = self.main_mid_mask(29, 27)\n",
    "        self.mask3 = self.mask3.to(device)\n",
    "        self.mask4 = self.main_mid_mask(27, 25)\n",
    "        self.mask4 = self.mask4.to(device) \n",
    "        self.mask5 = self.main_mid_mask(25, 23)\n",
    "        self.mask5 = self.mask5.to(device)\n",
    "        self.mask6 = self.main_mid_mask(23, 21)\n",
    "        self.mask6 = self.mask6.to(device)\n",
    "        self.mask7 = self.main_mid_mask(21, 19)\n",
    "        self.mask7 = self.mask7.to(device)\n",
    "\n",
    "        # or pure fcfc #################################\n",
    "        # self.fcfc1 = nn.Linear(49, 20, bias=False)\n",
    "        # self.fcfc2 = nn.Linear(20, 5, bias=False)\n",
    "        # self.fcfc3 = nn.Linear(5, 5, bias=False)\n",
    "\n",
    "\n",
    "    def main_fst_mask(self, in_dim, out_dim):\n",
    "        assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (out_dim-in_dim==6), \"gen_main_fst_mask: in_dim and out_dim must be odd and in_dim-out_dim=6\"\n",
    "        mask = torch.zeros(out_dim, in_dim)\n",
    "        for i in range(out_dim):\n",
    "            if i % 2 == 0:  # For every second row\n",
    "                idx_a = max(0, i-6)\n",
    "                adx_b = min(max(0, i-4), in_dim-1)\n",
    "                idx_c = min(max(0, i-3), in_dim-1)\n",
    "                idx_d = min(max(0, i-2), in_dim-1)\n",
    "                idx_e = min(i, in_dim-1)\n",
    "                # print(idx_a, adx_b, idx_c, idx_d, idx_e)\n",
    "                index_list = [idx_a, adx_b, idx_c, idx_d, idx_e]\n",
    "                mask[i, index_list] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def main_mid_mask(self, in_dim, out_dim):\n",
    "        assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (in_dim-out_dim==2), \"main_mid_mask: in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "        mask = torch.zeros(out_dim, in_dim)\n",
    "        for i in range(out_dim):\n",
    "            if i % 2 == 0:  # For every second row\n",
    "                idx_a = max(0, i-2)\n",
    "                adx_b = min(max(0, i), in_dim-1)\n",
    "                idx_c = min(max(0, i+1), in_dim-1)\n",
    "                idx_d = min(max(0, i+2), in_dim-1)\n",
    "                idx_e = min(max(0, i+4), in_dim-1)\n",
    "                # print(idx_a, adx_b, idx_c, idx_d, idx_e)\n",
    "                index_list = [idx_a, adx_b, idx_c, idx_d, idx_e]\n",
    "                mask[i, index_list] = 1\n",
    "        \n",
    "        return mask \n",
    "    \n",
    "    \n",
    "    def forward(self, xx):\n",
    "        assert len(xx.shape) == 3, \"Main. len(x.shape) must be 3, but got {}\".format(len(xx.shape))\n",
    "        assert (xx.shape[1]==49) and (xx.shape[2]==25), \"Main. x.shape[1] and x.shape[2] must be 25, but got {} and {}\".format(xx.shape[1], xx.shape[2])\n",
    "        # the 25 input to 25 submodels\n",
    "        sub_results = []\n",
    "        for i in range(49):\n",
    "            sub_results.append(self.submodels[i](xx[:, i, :]))\n",
    "        \n",
    "        sub_results = torch.cat(sub_results, dim=1)\n",
    "        if self.logg: print('sub_results:',sub_results.shape)\n",
    "        assert sub_results.shape[1] == 49, \"sub_results.shape[1] must be 49, but got {}\".format(sub_results.shape[1])\n",
    "\n",
    "        # # directly use fcfc to process the 25-dim vector\n",
    "        # x1c = self.fcfc1(sub_results)\n",
    "        # x1c = torch.tanh(x1c)\n",
    "        # x2 = self.fcfc2(x1c)\n",
    "        # x2 = torch.tanh(x2)\n",
    "        # x3 = self.fcfc3(x2)\n",
    "        # x3 = torch.tanh(x3)\n",
    "        # output = torch.cat([x2, x3], dim=1) # (b, 10)\n",
    "        ############################################################\n",
    "\n",
    "        # process the 49-dim vector\n",
    "        self.fc0.weight.data *= self.mask0\n",
    "        x0 = self.fc0(sub_results[:, 0:27]) # (b, 33)\n",
    "        x0 = torch.tanh(x0) # (b, 33)\n",
    "\n",
    "        assert torch.sum(x0[:, [7,9,11,13,15,17,19,21,23,25]]) == 0, \"x0[:, [7,9,11,13,15,17,19,21,23,25]] must be 0, but got {}\".format(x0[:, [7,9,11,13,15,17,19,21,23,25]])\n",
    "        x0_copy = x0.clone()\n",
    "        x0_copy[:, [7,9,11,13,15,17,19,21,23,25]] += sub_results[:, [27,28,29,30,31,32,33,34,35,36]]\n",
    "        x0 = x0_copy\n",
    "        # x0c = torch.cat([ x0[:, 0:7], sub_results[:, 27:28], x0[:, 8:9], sub_results[:, 28:29], x0[:, 10:11], sub_results[:, 29:30], \n",
    "        #                  x0[:, 12:13], sub_results[:, 30:31], x0[:, 14:15], sub_results[:, 31:32], x0[:, 16:17], sub_results[:, 32:33], \n",
    "        #                  x0[:, 18:19], sub_results[:, 33:34], x0[:, 20:21], sub_results[:, 34:35], x0[:, 22:23], sub_results[:, 35:36], \n",
    "        #                  x0[:, 24:25], sub_results[:, 36:37], x0[:, 26:]], dim=1) # (b, 33)\n",
    "        self.fc1.weight.data *= self.mask1\n",
    "        x1 = self.fc1(x0)\n",
    "        x1 = torch.tanh(x1) # (b, 31)\n",
    "\n",
    "        assert torch.sum(x1[:, [9,11,13,15,17,19,21]]) == 0, \"x1[:, [9,11,13,15,17,19,21]] must be 0, but got {}\".format(x1[:, [9,11,13,15,17,19,21]])\n",
    "        x1_copy = x1.clone()\n",
    "        x1_copy[:, [9,11,13,15,17,19,21]] += sub_results[:, [37,38,39,40,41,42,43]]\n",
    "        x1 = x1_copy\n",
    "        # x1c = torch.cat([ x1[:, 0:9], sub_results[:, 37:38], x1[:, 10:11], sub_results[:, 38:39], x1[:, 12:13], sub_results[:, 39:40],\n",
    "        #                  x1[:, 14:15], sub_results[:, 40:41], x1[:, 16:17], sub_results[:, 41:42], x1[:, 18:19], sub_results[:, 42:43],\n",
    "        #                  x1[:, 20:21], sub_results[:, 43:44], x1[:, 22:]], dim=1) # (b, 31)\n",
    "        self.fc2.weight.data *= self.mask2\n",
    "        x2 = self.fc2(x1)\n",
    "        x2_copy = x2.clone()\n",
    "        x2_copy[:, [0,2,4,6,8,10,12,14,16,18,20,22,24,26,28]] += x0[:,[2,4,6,8,10,12,14,16,18,20,22,24,26,28,30]] # jump connection\n",
    "        x2 = x2_copy\n",
    "        x2 = torch.tanh(x2) # (b, 29)\n",
    "\n",
    "        assert torch.sum(x2[:, [11,13,15,17]]) == 0, \"x2[:, [11,13,15,17]] must be 0, but got {}\".format(x2[:, [11,13,15,17]])\n",
    "        x2_copy = x2.clone()\n",
    "        x2_copy[:, [11,13,15,17]] += sub_results[:, [44,45,46,47]]\n",
    "        x2 = x2_copy\n",
    "        # x2c = torch.cat([ x2[:, 0:11], sub_results[:, 44:45], x2[:, 12:13], sub_results[:, 45:46], x2[:, 14:15], sub_results[:, 46:47],\n",
    "        #                 x2[:, 16:17], sub_results[:, 47:48], x2[:, 18:]], dim=1) # (b, 29)\n",
    "        self.fc3.weight.data *= self.mask3\n",
    "        x3 = self.fc3(x2)\n",
    "        x3_copy = x3.clone()\n",
    "        x3_copy[:, [0,2,4,6,8,10,12,14,16,18,20,22,24,26]] += x1[:, [2,4,6,8,10,12,14,16,18,20,22,24,26,28]] # jump connection\n",
    "        x3 = x3_copy\n",
    "        x3 = torch.tanh(x3) # (b, 27)\n",
    "\n",
    "        assert torch.sum(x3[:, [13]]) == 0, \"x3[:, [13]] must be 0, but got {}\".format(x3[:, [13]])\n",
    "        x3_copy = x3.clone()\n",
    "        x3_copy[:, [13]] += sub_results[:, [48]]\n",
    "        x3 = x3_copy\n",
    "        self.fc4.weight.data *= self.mask4\n",
    "        x4 = self.fc4(x3)\n",
    "        x4_copy = x4.clone()\n",
    "        x4_copy[:, [0,2,4,6,8,10,12,14,16,18,20,22,24]] += x2[:, [2,4,6,8,10,12,14,16,18,20,22,24,26]] # jump connection\n",
    "        x4 = x4_copy\n",
    "        x4 = torch.tanh(x4) # (b, 25)\n",
    "\n",
    "        self.fc5.weight.data *= self.mask5\n",
    "        x5 = self.fc5(x4)\n",
    "        x5_copy = x5.clone()\n",
    "        x5_copy[:, [0,2,4,6,8,10,12,14,16,18,20,22]] += x3[:, [2,4,6,8,10,12,14,16,18,20,22,24]] # jump connection\n",
    "        x5 = x5_copy\n",
    "        x5 = torch.tanh(x5) # (b, 23)\n",
    "\n",
    "        self.fc6.weight.data *= self.mask6\n",
    "        x6 = self.fc6(x5)\n",
    "        x6_copy = x6.clone()\n",
    "        x6_copy[:, [0,2,4,6,8,10,12,14,16,18,20]] += x4[:, [2,4,6,8,10,12,14,16,18,20,22]] # jump connection\n",
    "        x6 = x6_copy\n",
    "        x6 = torch.tanh(x6) # (b, 21)\n",
    "\n",
    "        self.fc7.weight.data *= self.mask7\n",
    "        x7 = self.fc7(x6)\n",
    "        x7_copy = x7.clone()\n",
    "        x7_copy[:, [0,2,4,6,8,10,12,14,16,18]] += x5[:, [2,4,6,8,10,12,14,16,18,20]] # jump connection\n",
    "        x7 = x7_copy\n",
    "        x7 = torch.tanh(x7) # (b, 19)\n",
    "\n",
    "        output = x7[:, [0,2,4,6,8,10,12,14,16,18]] # (b, 10)\n",
    "        \n",
    "\n",
    "        return output\n",
    "\n",
    "# use randn input to test main model\n",
    "# model = MainModel()\n",
    "# x = torch.randn(1, 49, 25)\n",
    "# model(x) # (1, 10)\n",
    "\n",
    "# train the model ********************************************************\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MainModel(device).to(device)\n",
    "model.load_state_dict(torch.load('data/dianet_patch_mnist_49_25.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# train\n",
    "model.train()\n",
    "max_acc, min_loss = 0.9526, 0.82\n",
    "for epoch in range(200):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        images = images.view(-1, 49, 25)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "\n",
    "    # test model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.view(-1, 49, 25)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # save best model, both accuracy and loss\n",
    "        if correct/total > max_acc: #and loss.item() < min_loss:\n",
    "            max_acc = correct/total\n",
    "            min_loss = loss.item()\n",
    "            torch.save(model.state_dict(), 'data/dianet_patch_mnist_49_25.pth') # 0.9526\n",
    "            print('saved at epoch {}, acc {}, loss {}'.format(epoch, max_acc, min_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainModel(\n",
      "  (submodels): ModuleList(\n",
      "    (0): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (1): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (2): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (3): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (4): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (5): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (6): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (7): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (8): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (9): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (10): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (11): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (12): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (13): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (14): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (15): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (16): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (17): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (18): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (19): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (20): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (21): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (22): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (23): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (24): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (25): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (26): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (27): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (28): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (29): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (30): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (31): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (32): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (33): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (34): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (35): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (36): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (37): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (38): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (39): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (40): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (41): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (42): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (43): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (44): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (45): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (46): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (47): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "    (48): SubModel(\n",
      "      (fc0): Linear(in_features=13, out_features=11, bias=False)\n",
      "      (fc1): Linear(in_features=11, out_features=9, bias=False)\n",
      "      (fc2): Linear(in_features=9, out_features=7, bias=False)\n",
      "      (fc3): Linear(in_features=7, out_features=5, bias=False)\n",
      "      (fc4): Linear(in_features=5, out_features=3, bias=False)\n",
      "      (fc5): Linear(in_features=3, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (fc0): Linear(in_features=27, out_features=33, bias=False)\n",
      "  (fc1): Linear(in_features=33, out_features=31, bias=False)\n",
      "  (fc2): Linear(in_features=31, out_features=29, bias=False)\n",
      "  (fc3): Linear(in_features=29, out_features=27, bias=False)\n",
      "  (fc4): Linear(in_features=27, out_features=25, bias=False)\n",
      "  (fc5): Linear(in_features=25, out_features=23, bias=False)\n",
      "  (fc6): Linear(in_features=23, out_features=21, bias=False)\n",
      "  (fc7): Linear(in_features=21, out_features=19, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for x0:\n",
      " tensor([[0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Gradient for x1:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comparch\\AppData\\Local\\Temp\\ipykernel_21328\\3330320129.py:22: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  print(\"Gradient for x1:\\n\", x1.grad)\n"
     ]
    }
   ],
   "source": [
    "# Assume x0 and x1 are the outputs of previous layers\n",
    "x0 = torch.randn(10, 33, requires_grad=True)  # batch size 10, feature size 33\n",
    "x1 = torch.randn(10, 31, requires_grad=True)  # batch size 10, feature size 31\n",
    "\n",
    "# Create a copy of x1\n",
    "x1_copy = x1.clone()\n",
    "\n",
    "# Perform the addition operation on the copy\n",
    "x1_copy[:, [0,2,4,6,8]] += x0[:, [2,4,6,8,10]]\n",
    "\n",
    "# Replace x1 with the modified copy\n",
    "x1 = x1_copy\n",
    "\n",
    "# Compute a dummy loss and backpropagate\n",
    "loss = x1.sum()\n",
    "loss.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(\"Gradient for x0:\\n\", x0.grad)\n",
    "print(\"Gradient for x1:\\n\", x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# write some rules\n",
    "# matrix (9,11)\n",
    "'''\n",
    "rowid:colid has 1, others are 0\n",
    "0:0,1,2,4\n",
    "2:0,2,3,4,6\n",
    "4:2,4,5,6,7\n",
    "6:4,6,7,8,10\n",
    "8:6,8,9,10\n",
    "'''\n",
    "import torch\n",
    "\n",
    "def generate_mask(in_dim, out_dim):\n",
    "    assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (in_dim-out_dim==2), \"in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "    mask = torch.zeros(out_dim, in_dim)\n",
    "    for i in range(out_dim):\n",
    "        if i % 2 == 0:  # For every second row\n",
    "            start_index = i  # Determine start index for the 1's in this row\n",
    "            mask[i, start_index:start_index+3] = 1\n",
    "            if i >= 2 and i <= out_dim-3: \n",
    "                mask[i, start_index-2] = 1\n",
    "                mask[i, start_index+3+1] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# test generate_mask\n",
    "mask = generate_mask(11, 9)\n",
    "print(mask)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0\n",
      "0 0 0 0 2\n",
      "0 0 1 2 4\n",
      "0 2 3 4 6\n",
      "2 4 5 6 8\n",
      "4 6 7 8 10\n",
      "6 8 9 10 12\n",
      "8 10 11 12 14\n",
      "10 12 13 14 16\n",
      "12 14 15 16 18\n",
      "14 16 17 18 20\n",
      "16 18 19 20 22\n",
      "18 20 21 22 24\n",
      "20 22 23 24 26\n",
      "22 24 25 26 26\n",
      "24 26 26 26 26\n",
      "26 26 26 26 26\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def main_fst_mask(in_dim, out_dim):\n",
    "    assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (out_dim-in_dim==6), \"in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "    mask = torch.zeros(out_dim, in_dim)\n",
    "    for i in range(out_dim):\n",
    "        if i % 2 == 0:  # For every second row\n",
    "            idx_a = max(0, i-6)\n",
    "            adx_b = min(max(0, i-4), in_dim-1)\n",
    "            idx_c = min(max(0, i-3), in_dim-1)\n",
    "            idx_d = min(max(0, i-2), in_dim-1)\n",
    "            idx_e = min(i, in_dim-1)\n",
    "            print(idx_a, adx_b, idx_c, idx_d, idx_e)\n",
    "            index_list = [idx_a, adx_b, idx_c, idx_d, idx_e]\n",
    "            mask[i, index_list] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# test generate_mask\n",
    "mask = main_fst_mask(27, 33)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 2 4\n",
      "0 2 3 4 6\n",
      "2 4 5 6 8\n",
      "4 6 7 8 8\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def main_mid_mask(in_dim, out_dim):\n",
    "    assert (in_dim % 2 == 1) and (out_dim % 2 == 1) and (in_dim-out_dim==2), \"main_mid_mask: in_dim and out_dim must be odd and in_dim-out_dim=2\"\n",
    "    mask = torch.zeros(out_dim, in_dim)\n",
    "    for i in range(out_dim):\n",
    "        if i % 2 == 0:  # For every second row\n",
    "            idx_a = max(0, i-2)\n",
    "            adx_b = min(max(0, i), in_dim-1)\n",
    "            idx_c = min(max(0, i+1), in_dim-1)\n",
    "            idx_d = min(max(0, i+2), in_dim-1)\n",
    "            idx_e = min(max(0, i+4), in_dim-1)\n",
    "            print(idx_a, adx_b, idx_c, idx_d, idx_e)\n",
    "            index_list = [idx_a, adx_b, idx_c, idx_d, idx_e]\n",
    "            mask[i, index_list] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# test generate_mask\n",
    "mask = main_mid_mask(9, 7)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_mask(input_dim, output_dim):\n",
    "    mask = np.zeros((output_dim, input_dim))  # Create an array of zeros\n",
    "\n",
    "    for i in range(output_dim):\n",
    "        if i % 2 == 0:  # For every second row\n",
    "            start_index = i  # Determine start index for the 1's in this row\n",
    "            mask[i, start_index:start_index+3] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Test the function with linear(7,5)\n",
    "mask = generate_mask(13, 11)\n",
    "print(mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaPy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
